{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2dd70b-c212-451f-85c8-4bef38bdc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,1280)\n",
    "cam.set(4,1024)\n",
    "cam.set(15, 0.1)\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")\n",
    "classNames= []\n",
    "classFile = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/coco.names'\n",
    "with open(classFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fbf3c-d8a4-4f72-bd4b-1b709e23be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39    1\n",
      "0    1\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "17    1\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "0    1\n",
      "39    1\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "39    1\n"
     ]
    }
   ],
   "source": [
    "modelConfiguration='C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.cfg'\n",
    "modelWeights = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.weights'\n",
    "net = cv2.dnn.readNetFromDarknet (modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend (cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn. DNN_TARGET_CPU)\n",
    "whT = 320\n",
    "confThreshold = 0.5\n",
    "nmsThreshold=0.3\n",
    "speaks={}\n",
    "def findobjects(outputs,img):\n",
    "    freq={}\n",
    "    hT, wT, cT = img.shape\n",
    "    bbox=[]\n",
    "    classIds = []\n",
    "    confs = [] \n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores =det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                w,h = int(det [2]*wT),int(det[3]*hT) #21\n",
    "                x,y = int((det[0]*wT)-w/2),int((det[1]*hT)-h/2)\n",
    "                bbox.append ([x,y,w,h])\n",
    "                classIds.append (classId)\n",
    "                confs.append (float(confidence))\n",
    "    indices = cv2.dnn. NMSBoxes (bbox, confs,confThreshold,nmsThreshold)\n",
    "    for i in indices:\n",
    "        res=classNames[classIds[i]]\n",
    "        box=bbox[i]\n",
    "        x,y,w,h= box[0],box[1],box[2],box[3]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,255),2) #31\n",
    "        cv2.putText (img,f'{res.upper()} {int(confs[i]*100)}%',(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,255),2)\n",
    "        if speaks.get(classIds[i])==None:\n",
    "            speaks[classIds[i]]=time.time()\n",
    "            freq[classIds[i]]=1\n",
    "        else:\n",
    "            if time.time()-speaks[classIds[i]]>=15:\n",
    "                speaks[classIds[i]]=time.time()\n",
    "                freq[classIds[i]]=1\n",
    "            elif freq.get(classIds[i])!=None:\n",
    "                freq[classIds[i]]+=1\n",
    "    for key,value in freq.items():\n",
    "        if value >1:\n",
    "            speaker.speak(str(value)+classNames[key]+'s')\n",
    "        else:\n",
    "            speaker.speak(str(value)+classNames[key])\n",
    "        #print(str(key)+ \"    \"+str(value)) \n",
    "        \n",
    "while True:\n",
    "    success, img =cam.read()\n",
    "    blob=cv2.dnn.blobFromImage(img,1/255, (whT,whT),[0,0,0],1,crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerNames=net.getLayerNames()\n",
    "    outputNames = [layerNames[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "    outputs = net.forward(outputNames)\n",
    "    findobjects(outputs,img)\n",
    "    #print(\"--------------------------------------------------------------------\")\n",
    "    cv2.imshow('Image',img)\n",
    "    cv2.waitKey(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba290333-3cbf-44e9-a779-0ee419e6dd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nconfigPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.cfg'\\nweightPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.weights'\\nnet =cv2.dnn_DetectionModel(weightPath ,configPath)\\nnet.setInputSize(320,230)\\nnet.setInputScale(1.0/127.5)\\nnet.setInputMean((127.5, 127.5, 127.5))\\nspeaks={}\\ncnt=0\\nwhile True:\\n\\n    #cnt=cnt+1\\n    #print(cnt)\\n    success, img =cam.read()\\n    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (e,0,0), swapRB=True, crop=False)\\n    net.setInput(blob)\\n    output_layers_names = net.getUnconnectedOutLayersNames()\\n    layerOutputs net.forward(output_layers_names)\\n    classIds, confs, bbox =net.detect(img, confThreshold = 0.5)\\n    if len(classIds)!= 0:\\n        for classId in classIds.flatten():\\n            print(type(classId-1))\\n            print(classId)\\n            if speaks.get(classId-1)==None:\\n                speaks[classId-1]=time.time()\\n                speaker.Speak(classNames[classId-1])\\n            else:\\n                if time.time()-speaks[classId-1]>=30:\\n                    speaks[classId-1]=None\\n                \\n            \\n    cv2.imshow('output',img)\\n    cv2.waitKey(1)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "configPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.cfg'\n",
    "weightPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.weights'\n",
    "net =cv2.dnn_DetectionModel(weightPath ,configPath)\n",
    "net.setInputSize(320,230)\n",
    "net.setInputScale(1.0/127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "speaks={}\n",
    "cnt=0\n",
    "while True:\n",
    "\n",
    "    #cnt=cnt+1\n",
    "    #print(cnt)\n",
    "    success, img =cam.read()\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (e,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs net.forward(output_layers_names)\n",
    "    classIds, confs, bbox =net.detect(img, confThreshold = 0.5)\n",
    "    if len(classIds)!= 0:\n",
    "        for classId in classIds.flatten():\n",
    "            print(type(classId-1))\n",
    "            print(classId)\n",
    "            if speaks.get(classId-1)==None:\n",
    "                speaks[classId-1]=time.time()\n",
    "                speaker.Speak(classNames[classId-1])\n",
    "            else:\n",
    "                if time.time()-speaks[classId-1]>=30:\n",
    "                    speaks[classId-1]=None\n",
    "                \n",
    "            \n",
    "    cv2.imshow('output',img)\n",
    "    cv2.waitKey(1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec9525-d2b9-43df-a998-1bd7b44e4d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
