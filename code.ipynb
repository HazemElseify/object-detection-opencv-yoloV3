{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2dd70b-c212-451f-85c8-4bef38bdc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,1280)\n",
    "cam.set(4,1024)\n",
    "cam.set(15, 0.1)\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")\n",
    "classNames= []\n",
    "classFile = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/coco.names'\n",
    "with open(classFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fbf3c-d8a4-4f72-bd4b-1b709e23be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfiguration='C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.cfg'\n",
    "modelWeights = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.weights'\n",
    "net = cv2.dnn.readNetFromDarknet (modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend (cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn. DNN_TARGET_CPU)\n",
    "whT = 320\n",
    "confThreshold = 0.5\n",
    "nmsThreshold=0.3\n",
    "def findobjects(outputs,img):\n",
    "    hT, wT, cT = img.shape\n",
    "    bbox=[]\n",
    "    classIds = []\n",
    "    confs = [] \n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores =det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                w,h = int(det [2]*wT),int(det[3]*hT) #21\n",
    "                x,y = int((det[0]*wT)-w/2),int((det[1]*hT)-h/2)\n",
    "                bbox.append ([x,y,w,h])\n",
    "                classIds.append (classId)\n",
    "                confs.append (float(confidence))\n",
    "    indices = cv2.dnn. NMSBoxes (bbox, confs,confThreshold,nmsThreshold)\n",
    "    for i in indices:\n",
    "        box=bbox[i]\n",
    "        x,y,w,h= box[0],box[1],box[2],box[3]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,255),2) #31\n",
    "        cv2.putText (img,f'{classNames[classIds[i]].upper ()} {int(confs[i]*100)}%',(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,255),2)\n",
    "while True:\n",
    "    success, img =cam.read()\n",
    "    blob=cv2.dnn.blobFromImage(img,1/255, (whT,whT),[0,0,0],1,crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerNames=net.getLayerNames()\n",
    "    outputNames = [layerNames[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "    outputs = net.forward(outputNames)\n",
    "    findobjects(outputs,img)\n",
    "    cv2.imshow('Image',img)\n",
    "    cv2.waitKey(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe00d29-c79a-4505-a3a0-a92be0d918fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba290333-3cbf-44e9-a779-0ee419e6dd0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\concat_layer.cpp:104: error: (-201:Incorrect size of input array) Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HAZEMH~1\\AppData\\Local\\Temp/ipykernel_15344/3204026917.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#print(cnt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mclassIds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfThreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclassId\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassIds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\concat_layer.cpp:104: error: (-201:Incorrect size of input array) Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes'\n"
     ]
    }
   ],
   "source": [
    "configPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.cfg'\n",
    "weightPath = 'C:/Users/hazemhassan/Desktop/Object-detection-using-opencv-master/Object-detection-using-opencv-master/yolov3-spp.weights'\n",
    "net =cv2.dnn_DetectionModel(weightPath ,configPath)\n",
    "net.setInputSize(320,230)\n",
    "net.setInputScale(1.0/127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "speaks={}\n",
    "cnt=0\n",
    "while True:\n",
    "\n",
    "    #cnt=cnt+1\n",
    "    #print(cnt)\n",
    "    success, img =cam.read()\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (e,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs net.forward(output_layers_names)\n",
    "    classIds, confs, bbox =net.detect(img, confThreshold = 0.5)\n",
    "    if len(classIds)!= 0:\n",
    "        for classId in classIds.flatten():\n",
    "            print(type(classId-1))\n",
    "            print(classId)\n",
    "            if speaks.get(classId-1)==None:\n",
    "                speaks[classId-1]=time.time()\n",
    "                speaker.Speak(classNames[classId-1])\n",
    "            else:\n",
    "                if time.time()-speaks[classId-1]>=30:\n",
    "                    speaks[classId-1]=None\n",
    "                \n",
    "            \n",
    "    cv2.imshow('output',img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec9525-d2b9-43df-a998-1bd7b44e4d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
